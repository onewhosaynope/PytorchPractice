{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', '[', '\\\\', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '~', '©', '«', '»', 'Ё', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', 'Ь', 'Э', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', '–', '—', '’', '“', '”', '„', '•', '…', '№']\n"
     ]
    }
   ],
   "source": [
    "with open('poems.txt', 'r', encoding='utf8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "    \n",
    "\n",
    "all_characters = set(text)\n",
    "all_characters = sorted(all_characters)\n",
    "print(all_characters)\n",
    "# nums --> letters\n",
    "decoder = dict(enumerate(all_characters))\n",
    "# letters --> nums\n",
    "encoder = {char: index for index, char in decoder.items()}\n",
    "\n",
    "# build list of all encoded chars for text\n",
    "encoded_text = np.array([encoder[char] for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(encoded_text, num_unique_chars):\n",
    "    \n",
    "    # encoded_text --> batch of encoded text\n",
    "    # num_unique_chars --> len(set(text))\n",
    "    \n",
    "    one_hot = np.zeros((encoded_text.size, num_unique_chars))\n",
    "    one_hot = one_hot.astype(np.float32)\n",
    "    one_hot[np.arange(one_hot.shape[0]), encoded_text.flatten()] = 1.0\n",
    "    one_hot = one_hot.reshape((*encoded_text.shape, num_unique_chars))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(encoded_text, samp_per_batch=10, seq_len=50):\n",
    "    \n",
    "    # X : encoded text of length seq_len\n",
    "    # [0, 1, 2]\n",
    "    # [1, 2, 3]\n",
    "    \n",
    "    # Y : encoded text shifted by one\n",
    "    \n",
    "    # [1, 2, 3]\n",
    "    # [2, 3, 4]\n",
    "    \n",
    "    # how many chars per batch?\n",
    "    char_per_batch = samp_per_batch * seq_len \n",
    "    # how many batches can we make, given the len of encoded text?\n",
    "    num_batches_available = int(len(encoded_text) / char_per_batch)\n",
    "    # cut off the end of the encoded text, that won't fit evenly into a batch\n",
    "    encoded_text = encoded_text[ : num_batches_available * char_per_batch]\n",
    "    # reshape the encoded text\n",
    "    encoded_text = encoded_text.reshape((samp_per_batch, -1))\n",
    "    \n",
    "    for n in range(0, encoded_text.shape[1], seq_len):\n",
    "        \n",
    "        x = encoded_text[ : , n : n + seq_len]\n",
    "        # zeros array to the same shape as x\n",
    "        y = np.zeros_like(x)\n",
    "        \n",
    "        try:\n",
    "            y[:, :-1] = x[:, 1:]\n",
    "            y[:, -1] = encoded_text[:, n+seq_len]\n",
    "            \n",
    "        except:\n",
    "            y[:, :-1] = x[:, 1:]\n",
    "            y[:, -1] = encoded_text[:, 0]\n",
    "            \n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, all_chars, num_hidden=256, num_layers=4,drop_prob=0.5,use_gpu=False):\n",
    "        \n",
    "        \n",
    "        # SET UP ATTRIBUTES\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        #CHARACTER SET, ENCODER, and DECODER\n",
    "        self.all_chars = all_chars\n",
    "        self.decoder = dict(enumerate(all_chars))\n",
    "        self.encoder = {char: ind for ind,char in decoder.items()}\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(len(self.all_chars), num_hidden, num_layers, dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.fc_linear = nn.Linear(num_hidden, len(self.all_chars))\n",
    "      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "                  \n",
    "        lstm_output, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        drop_output = self.dropout(lstm_output)\n",
    "        drop_output = drop_output.contiguous().view(-1, self.num_hidden)\n",
    "        \n",
    "        final_out = self.fc_linear(drop_output)\n",
    "\n",
    "        return final_out, hidden\n",
    "    \n",
    "    \n",
    "    def hidden_state(self, batch_size):\n",
    "        '''\n",
    "        Used as separate method to account for both GPU and CPU users.\n",
    "        '''\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            \n",
    "            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda(),\n",
    "                     torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda())\n",
    "        else:\n",
    "            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden),\n",
    "                     torch.zeros(self.num_layers,batch_size,self.num_hidden))\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharModel(all_chars=all_characters,\n",
    "                 num_hidden=512,\n",
    "                 num_layers=3,\n",
    "                 drop_prob=0.5,\n",
    "                 use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[333824,\n",
       " 1048576,\n",
       " 2048,\n",
       " 2048,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2048,\n",
       " 2048,\n",
       " 1048576,\n",
       " 1048576,\n",
       " 2048,\n",
       " 2048,\n",
       " 83456,\n",
       " 163]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_param = []\n",
    "\n",
    "for p in model.parameters():\n",
    "    total_param.append(int(p.numel()))\n",
    "    \n",
    "total_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_percent = 0.9\n",
    "train_index = int(len(encoded_text) * train_percent)\n",
    "\n",
    "train_data = encoded_text[:train_index]\n",
    "val_data = encoded_text[train_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "epochs = 80\n",
    "batch_size = 250\n",
    "seq_len = 200\n",
    "tracker = 0\n",
    "num_char = max(encoded_text) + 1\n",
    "\n",
    "previous_loss = 100\n",
    "min_loss = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Step: 25 \n",
      "Current Validation Loss: 3.4680662155151367 \n",
      "Previous Loss: 100\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 0 Step: 50 \n",
      "Current Validation Loss: 3.4630939960479736 \n",
      "Previous Loss: 3.4680662155151367\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 1 Step: 75 \n",
      "Current Validation Loss: 3.4641547203063965 \n",
      "Previous Loss: 3.4630939960479736\n",
      "\n",
      "Epoch: 1 Step: 100 \n",
      "Current Validation Loss: 3.4623382091522217 \n",
      "Previous Loss: 3.4641547203063965\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 1 Step: 125 \n",
      "Current Validation Loss: 3.467604160308838 \n",
      "Previous Loss: 3.4623382091522217\n",
      "\n",
      "Epoch: 2 Step: 150 \n",
      "Current Validation Loss: 3.452200412750244 \n",
      "Previous Loss: 3.467604160308838\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 2 Step: 175 \n",
      "Current Validation Loss: 3.434162139892578 \n",
      "Previous Loss: 3.452200412750244\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 2 Step: 200 \n",
      "Current Validation Loss: 3.348487138748169 \n",
      "Previous Loss: 3.434162139892578\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 3 Step: 225 \n",
      "Current Validation Loss: 3.182598114013672 \n",
      "Previous Loss: 3.348487138748169\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 3 Step: 250 \n",
      "Current Validation Loss: 3.0348708629608154 \n",
      "Previous Loss: 3.182598114013672\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 3 Step: 275 \n",
      "Current Validation Loss: 2.976684331893921 \n",
      "Previous Loss: 3.0348708629608154\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 4 Step: 300 \n",
      "Current Validation Loss: 2.9350171089172363 \n",
      "Previous Loss: 2.976684331893921\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 4 Step: 325 \n",
      "Current Validation Loss: 2.8991594314575195 \n",
      "Previous Loss: 2.9350171089172363\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 5 Step: 350 \n",
      "Current Validation Loss: 2.863743543624878 \n",
      "Previous Loss: 2.8991594314575195\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 5 Step: 375 \n",
      "Current Validation Loss: 2.8114190101623535 \n",
      "Previous Loss: 2.863743543624878\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 5 Step: 400 \n",
      "Current Validation Loss: 2.7759320735931396 \n",
      "Previous Loss: 2.8114190101623535\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 6 Step: 425 \n",
      "Current Validation Loss: 2.7450153827667236 \n",
      "Previous Loss: 2.7759320735931396\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 6 Step: 450 \n",
      "Current Validation Loss: 2.7229256629943848 \n",
      "Previous Loss: 2.7450153827667236\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 6 Step: 475 \n",
      "Current Validation Loss: 2.6971168518066406 \n",
      "Previous Loss: 2.7229256629943848\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 7 Step: 500 \n",
      "Current Validation Loss: 2.678671360015869 \n",
      "Previous Loss: 2.6971168518066406\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 7 Step: 525 \n",
      "Current Validation Loss: 2.661367177963257 \n",
      "Previous Loss: 2.678671360015869\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 7 Step: 550 \n",
      "Current Validation Loss: 2.6466240882873535 \n",
      "Previous Loss: 2.661367177963257\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 8 Step: 575 \n",
      "Current Validation Loss: 2.625337839126587 \n",
      "Previous Loss: 2.6466240882873535\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 8 Step: 600 \n",
      "Current Validation Loss: 2.613525867462158 \n",
      "Previous Loss: 2.625337839126587\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 9 Step: 625 \n",
      "Current Validation Loss: 2.594330072402954 \n",
      "Previous Loss: 2.613525867462158\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 9 Step: 650 \n",
      "Current Validation Loss: 2.582324266433716 \n",
      "Previous Loss: 2.594330072402954\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 9 Step: 675 \n",
      "Current Validation Loss: 2.565086603164673 \n",
      "Previous Loss: 2.582324266433716\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 10 Step: 700 \n",
      "Current Validation Loss: 2.5529568195343018 \n",
      "Previous Loss: 2.565086603164673\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 10 Step: 725 \n",
      "Current Validation Loss: 2.5365726947784424 \n",
      "Previous Loss: 2.5529568195343018\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 10 Step: 750 \n",
      "Current Validation Loss: 2.517975091934204 \n",
      "Previous Loss: 2.5365726947784424\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 11 Step: 775 \n",
      "Current Validation Loss: 2.509263515472412 \n",
      "Previous Loss: 2.517975091934204\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 11 Step: 800 \n",
      "Current Validation Loss: 2.49226713180542 \n",
      "Previous Loss: 2.509263515472412\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 11 Step: 825 \n",
      "Current Validation Loss: 2.483597755432129 \n",
      "Previous Loss: 2.49226713180542\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 12 Step: 850 \n",
      "Current Validation Loss: 2.466463327407837 \n",
      "Previous Loss: 2.483597755432129\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 12 Step: 875 \n",
      "Current Validation Loss: 2.4501729011535645 \n",
      "Previous Loss: 2.466463327407837\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 13 Step: 900 \n",
      "Current Validation Loss: 2.437720537185669 \n",
      "Previous Loss: 2.4501729011535645\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 13 Step: 925 \n",
      "Current Validation Loss: 2.4257407188415527 \n",
      "Previous Loss: 2.437720537185669\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 13 Step: 950 \n",
      "Current Validation Loss: 2.4145734310150146 \n",
      "Previous Loss: 2.4257407188415527\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 14 Step: 975 \n",
      "Current Validation Loss: 2.3987209796905518 \n",
      "Previous Loss: 2.4145734310150146\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 14 Step: 1000 \n",
      "Current Validation Loss: 2.387942314147949 \n",
      "Previous Loss: 2.3987209796905518\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 14 Step: 1025 \n",
      "Current Validation Loss: 2.3743643760681152 \n",
      "Previous Loss: 2.387942314147949\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 15 Step: 1050 \n",
      "Current Validation Loss: 2.3652126789093018 \n",
      "Previous Loss: 2.3743643760681152\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 15 Step: 1075 \n",
      "Current Validation Loss: 2.3506455421447754 \n",
      "Previous Loss: 2.3652126789093018\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 15 Step: 1100 \n",
      "Current Validation Loss: 2.3434700965881348 \n",
      "Previous Loss: 2.3506455421447754\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 16 Step: 1125 \n",
      "Current Validation Loss: 2.327277183532715 \n",
      "Previous Loss: 2.3434700965881348\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 16 Step: 1150 \n",
      "Current Validation Loss: 2.31528377532959 \n",
      "Previous Loss: 2.327277183532715\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 17 Step: 1175 \n",
      "Current Validation Loss: 2.3048155307769775 \n",
      "Previous Loss: 2.31528377532959\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 17 Step: 1200 \n",
      "Current Validation Loss: 2.296262741088867 \n",
      "Previous Loss: 2.3048155307769775\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 17 Step: 1225 \n",
      "Current Validation Loss: 2.2879364490509033 \n",
      "Previous Loss: 2.296262741088867\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 18 Step: 1250 \n",
      "Current Validation Loss: 2.274446487426758 \n",
      "Previous Loss: 2.2879364490509033\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 18 Step: 1275 \n",
      "Current Validation Loss: 2.2642223834991455 \n",
      "Previous Loss: 2.274446487426758\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 18 Step: 1300 \n",
      "Current Validation Loss: 2.2544755935668945 \n",
      "Previous Loss: 2.2642223834991455\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 19 Step: 1325 \n",
      "Current Validation Loss: 2.24497389793396 \n",
      "Previous Loss: 2.2544755935668945\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 19 Step: 1350 \n",
      "Current Validation Loss: 2.2327616214752197 \n",
      "Previous Loss: 2.24497389793396\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 19 Step: 1375 \n",
      "Current Validation Loss: 2.2270121574401855 \n",
      "Previous Loss: 2.2327616214752197\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 20 Step: 1400 \n",
      "Current Validation Loss: 2.2154197692871094 \n",
      "Previous Loss: 2.2270121574401855\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 20 Step: 1425 \n",
      "Current Validation Loss: 2.2084598541259766 \n",
      "Previous Loss: 2.2154197692871094\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 21 Step: 1450 \n",
      "Current Validation Loss: 2.2023086547851562 \n",
      "Previous Loss: 2.2084598541259766\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 21 Step: 1475 \n",
      "Current Validation Loss: 2.190629005432129 \n",
      "Previous Loss: 2.2023086547851562\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 21 Step: 1500 \n",
      "Current Validation Loss: 2.186154842376709 \n",
      "Previous Loss: 2.190629005432129\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 22 Step: 1525 \n",
      "Current Validation Loss: 2.1805038452148438 \n",
      "Previous Loss: 2.186154842376709\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 22 Step: 1550 \n",
      "Current Validation Loss: 2.168710708618164 \n",
      "Previous Loss: 2.1805038452148438\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 22 Step: 1575 \n",
      "Current Validation Loss: 2.1602487564086914 \n",
      "Previous Loss: 2.168710708618164\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n",
      "Epoch: 23 Step: 1600 \n",
      "Current Validation Loss: 2.148754358291626 \n",
      "Previous Loss: 2.1602487564086914\n",
      "Error decreased!\n",
      "Saved model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set model to train\n",
    "model.train()\n",
    "\n",
    "\n",
    "# Check to see if using GPU\n",
    "if model.use_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    hidden = model.hidden_state(batch_size)\n",
    "    \n",
    "    \n",
    "    for x,y in generate_batches(train_data,batch_size,seq_len):\n",
    "        \n",
    "        tracker += 1\n",
    "        \n",
    "        # One Hot Encode incoming data\n",
    "        x = one_hot_encoder(x,num_char)\n",
    "        \n",
    "        # Convert Numpy Arrays to Tensor\n",
    "        \n",
    "        inputs = torch.from_numpy(x)\n",
    "        targets = torch.from_numpy(y)\n",
    "        \n",
    "        # Adjust for GPU if necessary\n",
    "        \n",
    "        if model.use_gpu:\n",
    "            \n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            \n",
    "        # Reset Hidden State\n",
    "        # If we dont' reset we would backpropagate through all training history\n",
    "        hidden = tuple([state.data for state in hidden])\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        lstm_output, hidden = model.forward(inputs,hidden)\n",
    "        loss = criterion(lstm_output,targets.view(batch_size*seq_len).long())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # POSSIBLE EXPLODING GRADIENT PROBLEM!\n",
    "        # LET\"S CLIP JUST IN CASE\n",
    "        nn.utils.clip_grad_norm_(model.parameters(),max_norm=5)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###################################\n",
    "        ### CHECK ON VALIDATION SET ######\n",
    "        #################################\n",
    "        \n",
    "        if tracker % 25 == 0:\n",
    "            \n",
    "            val_hidden = model.hidden_state(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            \n",
    "            for x,y in generate_batches(val_data,batch_size,seq_len):\n",
    "                \n",
    "                # One Hot Encode incoming data\n",
    "                x = one_hot_encoder(x, num_char)\n",
    "                \n",
    "\n",
    "                # Convert Numpy Arrays to Tensor\n",
    "\n",
    "                inputs = torch.from_numpy(x)\n",
    "                targets = torch.from_numpy(y)\n",
    "\n",
    "                # Adjust for GPU if necessary\n",
    "\n",
    "                if model.use_gpu:\n",
    "\n",
    "                    inputs = inputs.cuda()\n",
    "                    targets = targets.cuda()\n",
    "                    \n",
    "                # Reset Hidden State\n",
    "                # If we dont' reset we would backpropagate through \n",
    "                # all training history\n",
    "                val_hidden = tuple([state.data for state in val_hidden])\n",
    "                \n",
    "                lstm_output, val_hidden = model.forward(inputs,val_hidden)\n",
    "                val_loss = criterion(lstm_output,targets.view(batch_size*seq_len).long())\n",
    "                val_losses.append(val_loss.item())\n",
    "            \n",
    "            # Reset to training model after val for loop\n",
    "            model.train()\n",
    "    \n",
    "            current_loss = val_loss.item()\n",
    "        \n",
    "            print(f\"Epoch: {i} Step: {tracker} \\nCurrent Validation Loss: {current_loss} \\nPrevious Loss: {previous_loss}\")\n",
    "\n",
    "            if (current_loss < previous_loss):\n",
    "                if (current_loss < min_loss):\n",
    "                    print('Error decreased!')\n",
    "                    torch.save(model.state_dict(), 'min_hidden512_layers3_poems.net')\n",
    "                    print('Saved model.')\n",
    "                    min_loss = current_loss\n",
    "                else:\n",
    "                    print('Error increased!')\n",
    "                \n",
    "            previous_loss = val_loss.item()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'hidden512_layers3_poems.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_char(model, char, hidden=None, k=1):\n",
    "    \n",
    "    encoded_text = model.encoder[char]\n",
    "    encoded_text = np.array([[encoded_text]])\n",
    "    encoded_text = one_hot_encoder(encoded_text, len(model.all_chars))\n",
    "    inputs = torch.from_numpy(encoded_text)\n",
    "    \n",
    "    if model.use_gpu:\n",
    "        inputs = inputs.cuda()\n",
    "        \n",
    "    hidden = tuple([state.data for state in hidden])\n",
    "    \n",
    "    lstm_out, hidden = model(inputs, hidden)\n",
    "    \n",
    "    probs = F.softmax(lstm_out, dim=1).data\n",
    "    \n",
    "    if model.use_gpu:\n",
    "        probs = probs.cpu()\n",
    "        \n",
    "    probs, index_positions = probs.topk(k)\n",
    "    \n",
    "    index_positions = index_positions.numpy().squeeze()\n",
    "    \n",
    "    probs = probs.numpy().flatten()\n",
    "    \n",
    "    probs = probs / probs.sum()\n",
    "    \n",
    "    char = np.random.choice(index_positions, p=probs)\n",
    "    \n",
    "    return model.decoder[char], hidden\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, size, seed='Дело было ', k=1):\n",
    "    \n",
    "    if model.use_gpu:\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model.cpu()\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    output_chars = [c for c in seed]\n",
    "    \n",
    "    hidden = model.hidden_state(1)\n",
    "    \n",
    "    for char in seed:\n",
    "        char, hidden = predict_next_char(model, char, hidden, k=k)\n",
    "        \n",
    "    output_chars.append(char)\n",
    "    \n",
    "    for i in range(size):\n",
    "        \n",
    "        char, hidden = predict_next_char(model, output_chars[-1], hidden, k=k)\n",
    "        \n",
    "        output_chars.append(char)\n",
    "        \n",
    "    return ''.join(output_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharModel(\n",
    "    all_chars=all_characters,\n",
    "    num_hidden=512,\n",
    "    num_layers=3,\n",
    "    drop_prob=0.5,\n",
    "    use_gpu=True,\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load('min_hidden512_layers3_poems.net'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(model, 3000, seed='Сердце ', k=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
